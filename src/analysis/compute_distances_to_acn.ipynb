{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "os.chdir('/home/adri/Projects/phd/bias_2')\n",
    "from generate_toy_network import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 53/150 [03:42<06:47,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n",
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [57:23<00:00, 41.84s/it]"
     ]
    }
   ],
   "source": [
    "replicates = [1, 2, 3, 4, 5]\n",
    "upper_thresholds = [0.9, 0.95, 1]\n",
    "thresholds = np.linspace(0, 0.2, 10)\n",
    "\n",
    "total = 5*3*len(thresholds)\n",
    "\n",
    "# set the tqdm bar\n",
    "pbar = tqdm(total=total)\n",
    "\n",
    "for upper_threshold in upper_thresholds:\n",
    "\n",
    "    for path in glob(f'results/allosteric_network_distance/ACN_filering_thresholds/ACN_*_{upper_threshold}'):\n",
    "        \n",
    "        shortest_path_path = f'{path}/transition_matrices/WT_transition_matrix.csv'\n",
    "\n",
    "        for replicate in replicates:\n",
    "            \n",
    "            graph_path = f'{path}/nw_pickles/WT/{replicate}.pickle'\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                \n",
    "                threshold_str = str(threshold).split('.')[1][:3]\n",
    "                df_path = f'{path}/allosteric_network_distance/dist_to_pathway_r{replicate}_t{threshold_str}.csv'\n",
    "                random_df_path = f'{path}/allosteric_network_distance/random_dist_to_pathway_r{replicate}_t{threshold_str}.csv'\n",
    "\n",
    "                if os.path.exists(df_path) and os.path.exists(random_df_path):\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "    \n",
    "                graph = preprocess_graph(graph_path)\n",
    "                \n",
    "                shortest_pathway_df = parse_pathway_data(shortest_path_path)\n",
    "                shortest_pathway = path_df_to_list(shortest_pathway_df, float(threshold))\n",
    "                \n",
    "\n",
    "                gi_preferred_mutants = get_gi_preferred_mutants()\n",
    "                \n",
    "                weighted_df = get_distances_to_shortest_pathway(graph, shortest_pathway, gi_preferred_mutants, weighted=True)\n",
    "                df = get_distances_to_shortest_pathway(graph, shortest_pathway, gi_preferred_mutants, weighted=False)\n",
    "\n",
    "                # Generate Null hypothesis random data\n",
    "                n_nodes = len(gi_preferred_mutants)\n",
    "                random_data_df = gen_random_data(graph, n_nodes, shortest_pathway, n_replicates=1000, weighted=False)\n",
    "                random_data_df['type'] = 'unweighted'\n",
    "                weighted_random_data_df = gen_random_data(graph, n_nodes, shortest_pathway, n_replicates=1000, weighted=True)\n",
    "                weighted_random_data_df['type'] = 'weighted'\n",
    "                random_data_df = pd.concat([random_data_df, weighted_random_data_df])\n",
    "                \n",
    "                weighted_df['theshold'] = threshold\n",
    "                weighted_df['type'] = 'weighted'\n",
    "\n",
    "                df['theshold'] = threshold\n",
    "                df['type'] = 'unweighted'\n",
    "                \n",
    "                df = pd.concat([weighted_df, df])\n",
    "\n",
    "                os.makedirs(f'{path}/allosteric_network_distance', exist_ok=True)\n",
    "                \n",
    "                df.to_csv(df_path)\n",
    "                \n",
    "                random_data_df.to_csv(random_df_path)\n",
    "\n",
    "                pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
